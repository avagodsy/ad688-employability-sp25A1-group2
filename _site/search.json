[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "research_introduction.html#references",
    "href": "research_introduction.html#references",
    "title": "Research Introduction: AI vs. Non-AI Careers",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "research_introduction.html#introduction",
    "href": "research_introduction.html#introduction",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "research_introduction.html#literature-review",
    "href": "research_introduction.html#literature-review",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "Literature Review",
    "text": "Literature Review\nIn this report, researchers Alekseeva et. al. (Alekseeva et al. ((2021))) recapped their findings of the demand for AI skills in the U.S. economy. The authors point out that it can be difficult to find data regarding companies’ demand for AI skills, so they used job posting data. They defined AI job postings as those that included “artificial intelligence”, “machine vision”, “deep learning” or “speech recognition”. They found that larger firms (measured by market capitalization, cash holdings, and investments in R&D) tended to pay more of a premium for AI skills. Firms with more demand for AI skills also offered high salaries in non-AI jobs than firms with less demand for AI skills.\n\nThe results also showed that while IT-related industries have the highest demand for AI skills, there is significant growth across a wide range of industries outside of IT as well. Across all industries, AI skills hold an average of an 11% wage premium. The job with the largest premium is Management; the authors surmise that this means AI has the greatest value when combined with organizational knowledge.\n\nAuthors Pabilonia and Vernon outline differences in compensation for remote and in-office roles (Pabilonia and Vernon ((2025))). Using data from American Time Use Survey (ATUS) they note that remote work has increased in the US since 2020 (causal connection with the COVID-19 pandemic), and importantly “remote workers in most occupations earned a wage premium”. The authors performed extensive mathematical analysis within the paper, determining that in 2021 there was a 13.3% premium for remote work versus in-office work. Wages within the paper are indicated as being “determined by a number of factors, including job tasks, productivity differences, compensating differentials for job amenities, search frictions, and monopsony power, among others”. The authors also touched on disparity in pay within the principal city of the large metropolitan statistical area (MSA), noting that the wage premium for individuals working within the MSA was smaller (12.6%) than those working outside the 15 largest MDAs (14.5%).\n\nCard et. al. (Card, Rothstein, and Yi ((2023))) discuss the locale for the highest paid jobs within the US. Unsurprisingly, using “data from the Longitudinal Employer-Household Dynamics program” the authors demonstrate connections between location and salary. Regions in major metropolitans and large industries have wage premiums up to 18% higher than national averages. The authors theorize that larger cities pay more due to their ability to attract and retain higher-skilled workers and the likely presence of large companies to support the talent. The authors do however also find that despite the higher wages in the major commuting zones (CZs), local costs “fully offset local pay premiums, implying that workers who move to larger CZs have no higher net-of-housing consumption”. This leads to the understanding that while more highly compensated in major metropolitan areas, the cost of living consumes the wage premium.\n\nAccording to the U.S. Bureau of Labor Statistics (BLS) (Labor Statistics ((2024))), total employment is projected to grow by 4 percent between 2023 and 2033. There is also an expected increase in the number of jobs from 2023 to 2033 from 167.8 million to 17.46 million. Half of the forecasted job gains are expected to be in sectors such as healthcare, scientific and technical services. Whereas, the retail sector is more likely to lose jobs over the coming years.\n\nIndustries that will see the most significant wage growth from 2023 and 2033 are those that will have a strong demand for specialized labor. Healthcare and social assistance jobs will see a rise in high paying roles such as nurse practitioners and physical therapists assistants. This sector will experience continued growth due to skill labor shortages and aging population. The scientific and technical services sector is expected to grow by 10.5% and it includes high paying roles such as software developers, cybersecurity professionals and data scientists. Renewable Energy industries sector will see an increase in jobs over the years as demand for photovoltaic installers and wind turbines service technicians is increasing and are expected to be hired at competitive rates."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "index.html#literature-review",
    "href": "index.html#literature-review",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "Literature Review",
    "text": "Literature Review\nIn this report, researchers Alekseeva et. al. (Alekseeva et al. ((2021))) recapped their findings of the demand for AI skills in the U.S. economy. The authors point out that it can be difficult to find data regarding companies’ demand for AI skills, so they used job posting data. They defined AI job postings as those that included “artificial intelligence”, “machine vision”, “deep learning” or “speech recognition”. They found that larger firms (measured by market capitalization, cash holdings, and investments in R&D) tended to pay more of a premium for AI skills. Firms with more demand for AI skills also offered high salaries in non-AI jobs than firms with less demand for AI skills.\n\nThe results also showed that while IT-related industries have the highest demand for AI skills, there is significant growth across a wide range of industries outside of IT as well. Across all industries, AI skills hold an average of an 11% wage premium. The job with the largest premium is Management; the authors surmise that this means AI has the greatest value when combined with organizational knowledge.\n\nAuthors Pabilonia and Vernon outline differences in compensation for remote and in-office roles (Pabilonia and Vernon ((2025))). Using data from American Time Use Survey (ATUS) they note that remote work has increased in the US since 2020 (causal connection with the COVID-19 pandemic), and importantly “remote workers in most occupations earned a wage premium”. The authors performed extensive mathematical analysis within the paper, determining that in 2021 there was a 13.3% premium for remote work versus in-office work. Wages within the paper are indicated as being “determined by a number of factors, including job tasks, productivity differences, compensating differentials for job amenities, search frictions, and monopsony power, among others”. The authors also touched on disparity in pay within the principal city of the large metropolitan statistical area (MSA), noting that the wage premium for individuals working within the MSA was smaller (12.6%) than those working outside the 15 largest MDAs (14.5%).\n\nCard et. al. (Card, Rothstein, and Yi ((2023))) discuss the locale for the highest paid jobs within the US. Unsurprisingly, using “data from the Longitudinal Employer-Household Dynamics program” the authors demonstrate connections between location and salary. Regions in major metropolitans and large industries have wage premiums up to 18% higher than national averages. The authors theorize that larger cities pay more due to their ability to attract and retain higher-skilled workers and the likely presence of large companies to support the talent. The authors do however also find that despite the higher wages in the major commuting zones (CZs), local costs “fully offset local pay premiums, implying that workers who move to larger CZs have no higher net-of-housing consumption”. This leads to the understanding that while more highly compensated in major metropolitan areas, the cost of living consumes the wage premium.\n\nAccording to the U.S. Bureau of Labor Statistics (BLS) (Labor Statistics ((2024))), total employment is projected to grow by 4 percent between 2023 and 2033. There is also an expected increase in the number of jobs from 2023 to 2033 from 167.8 million to 17.46 million. Half of the forecasted job gains are expected to be in sectors such as healthcare, scientific and technical services. Whereas, the retail sector is more likely to lose jobs over the coming years.\n\nIndustries that will see the most significant wage growth from 2023 and 2033 are those that will have a strong demand for specialized labor. Healthcare and social assistance jobs will see a rise in high paying roles such as nurse practitioners and physical therapists assistants. This sector will experience continued growth due to skill labor shortages and aging population. The scientific and technical services sector is expected to grow by 10.5% and it includes high paying roles such as software developers, cybersecurity professionals and data scientists. Renewable Energy industries sector will see an increase in jobs over the years as demand for photovoltaic installers and wind turbines service technicians is increasing and are expected to be hired at competitive rates."
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('data\\lightcast_job_postings.csv')\n\n&lt;&gt;:4: SyntaxWarning:\n\ninvalid escape sequence '\\l'\n\n&lt;&gt;:4: SyntaxWarning:\n\ninvalid escape sequence '\\l'\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\3126061157.py:4: SyntaxWarning:\n\ninvalid escape sequence '\\l'\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\3126061157.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n\n\n\nWhich columns are irrelevant or redundant?\nID, URL, ACTIVE_URLS, DUPLICATES, LAST_UPDATED TIMESTAMP are irrelevant or redundant columns. They are mostly used for internal tracking and don’t contribute to the actual analysis of jobs, industries, and occupations.\nWhy are we removing multiple versions of NAICS/SOC codes?\nThe dataset contains multiple versions of industry NAICS and Occupational SOC which can be risky to keep, as there is risk of duplications and inconsistent groupings.\nHow will this improve analysis?\nThis will improve the analysis by enhancing the efficiency of the data; by having smaller datasets it will be easier to process and run data. It will also improve consistency because by having only one version of the data the risk of duplication will be low.\n\n\ncolumns_to_drop = [\n'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'EXPIRED', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW','BODY',\n'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS',\n'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP',\n'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING',\n'MSA_OUTGOING', 'MSA_NAME_OUTGOING','MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4','NAICS4_NAME',\n'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME',\n'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'LOT_OCCUPATION_GROUP_NAME',\n'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP',\n'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME',\n'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME',\n'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'MODELED_EXPIRED', 'MODELED_DURATION', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME',\n'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LIGHTCAST_SECTORS',\n'LIGHTCAST_SECTORS_NAME'\n]\ndata.drop(columns=columns_to_drop, inplace=True)\n\n\n\n\n\nAnswer the question: How should missing values be handled?\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Industry) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n\n\n# Fill missing values\ndata[\"SALARY\"].fillna(data[\"SALARY\"].median(), inplace=True)\ndata[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\", inplace=True)\ndata[\"REMOTE_TYPE_NAME\"].fillna(\"None, inplace=True\")\n\ndata.rename(columns={'NAICS_2022_6_NAME': 'INDUSTRY'}, inplace=True)\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\1830881447.py:7: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\1830881447.py:8: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n\ndata.dropna(thresh=len(data) * 0.5, axis=1, inplace=True)\n\n# Visualize missing data\nimport matplotlib as mpl\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Set global font settings\nmpl.rcParams['font.family'] = 'Verdana'\nmpl.rcParams['font.size'] = 14\nmpl.rcParams['text.color'] = 'black'\nmpl.rcParams['axes.labelcolor'] = 'black'\nmpl.rcParams['xtick.color'] = 'black'\nmpl.rcParams['ytick.color'] = 'black'\n\n# Define custom green-to-red colormap\ncustom_cmap = LinearSegmentedColormap.from_list(\n    'custom_green_red', ['#B14E53', '#78C2AD'], N=256\n)\n\n# Create the heatmap\nfig = plt.figure(figsize=(10, 6))\nax = msno.heatmap(data, cmap=custom_cmap)\n\n# Set the title\nplt.title(\"Missing Values Heatmap\", fontsize=18, fontweight='bold')\n\nplt.show()\nplt.savefig(\"figures/missing_values.png\")\n\n&lt;Figure size 960x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nThe heatmap shows a few missing values in the dataset. In this dataset most fields cluster near 1. The value 1 (dark blue) means the two columns have missing values together. 0.0 value (white) suggest there is no relationship.\n\n\n\n\ndata = data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Compute posting count per industry\ndata[\"posting_count\"] = data[\"ID\"].groupby(data[\"INDUSTRY\"]).transform(\"count\")\n\n# Summarize and sort top 25 industries\nindustry_summary = data.groupby(\"INDUSTRY\")[\"posting_count\"].first().sort_values(ascending=False).head(25)\n\n# Plot\nplt.figure(figsize=(12, 10))\nsns.barplot(\n    x=industry_summary.values,\n    y=industry_summary.index,\n    orient='h',\n    color='#6CC3D5'\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Top 25 Job Postings by Industry\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Number of Job Postings\", fontsize=14)\nplt.ylabel(\"Industry\", fontsize=14)\n\nplt.tight_layout()\nplt.show()\nplt.savefig(\"figures/top_postings.png\")\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Calculate average industry salary\ndata[\"AVERAGE_INDUSTRY_SALARY\"] = data[\"SALARY\"].groupby(data[\"INDUSTRY\"]).transform(\"mean\").round()\n\n# Get top 40 industries by average salary\ntop_40_industries = data.groupby(\"INDUSTRY\")[\"AVERAGE_INDUSTRY_SALARY\"].first().sort_values(ascending=False).head(40).index\nfiltered_data = data[data[\"INDUSTRY\"].isin(top_40_industries)]\n\n# Create figure with taller height\nplt.figure(figsize=(20, 14))  # Increased height from 10 to 14\n\n# Create boxplot with custom color\nsns.boxplot(\n    data=filtered_data,\n    x=\"INDUSTRY\",\n    y=\"SALARY\",\n    order=top_40_industries,\n    color='#F3969A'  # Custom box color\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Salary Distribution by Industry (Top 40 by Average Salary)\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Industry\", fontsize=14)\nplt.ylabel(\"Salary\", fontsize=14)\n\n# Rotate x-tick labels for readability\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\nplt.savefig(\"figures/salary_dist.png\")\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Clean and group remote types\nremote_grouped = data[\"REMOTE_TYPE_NAME\"].fillna(\"Onsite\").replace({\n    \"[None]\": \"Onsite\", \n    \"Not Remote\": \"Onsite\",\n    \"None\": \"Onsite\"\n})\n\n# Count values\nremote_counts = remote_grouped.value_counts()\n\n# Define colors matching labels (make sure the order matches remote_counts.index)\ncolor_map = {\n    \"Onsite\": \"#297C8A\",\n    \"Hybrid Remote\": \"#78C2AD\",\n    \"Remote\": \"#F3969A\"\n}\n\n# Get colors for the pie chart slices in the correct order, fallback to gray if missing\ncolors = [color_map.get(label, \"#cccccc\") for label in remote_counts.index]\n\n# Plot pie chart\nplt.figure(figsize=(8, 8))\nwedges, texts, autotexts = plt.pie(\n    remote_counts.values,\n    labels=remote_counts.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    textprops={'fontsize': 14, 'color': 'black'}\n)\n\n# Title with larger font\nplt.title(\"Remote vs. On-Site Jobs\", fontsize=18, fontweight='bold', pad=20)\n\n# Adjust autotext (percentage text) font size\nfor autotext in autotexts:\n    autotext.set_fontsize(14)\n\nplt.show()\nplt.savefig(\"figures/remote_onsite.png\")\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\n\n\n\n\nBar Chart: Job Postings by Industry\n\nMakes it easy to compare job postings across different industries.\n\nProvides a clear ranking that is simple to interpret.\n\nBoxplot: Salary Distribution by Industry\n\nShows medians, outliers, and summarizes salary distributions.\n\nAllows for comparisons between industries and helps detect salary variability.\n\nPie Chart: Job Location Types\n\nProvides a clear visual breakdown of remote versus on-site jobs within the dataset.\n\n\n\n\n\n\nBar Chart: Top 25 Industries by Job-Posting Volume\n\nThe distribution is skewed, showing demand concentrated in technology and professional services.\n\nA large portion of “unclassified industry” job postings suggests many jobs are not mapped to any industry.\n\nBoxplot: Salary Distribution by Industry\n\nSalaries across the 40 industries skew high, with medians generally in the $120k–$170k range.\n\nIndustries with higher medians and greater dispersions include software/semiconductors and consulting.\n\nSeveral industries have wide IQRs and many upper outliers, while some have less variability, indicating standardized pay.\n\nPie Chart: Job Location Types\n\n17% of jobs are remote, 3.1% are hybrid, and 1.6% are not remote.\n\nA large number of job postings do not specify whether the job is remote or on-site."
  },
  {
    "objectID": "data_analysis.html#dropping-unncessary-columns",
    "href": "data_analysis.html#dropping-unncessary-columns",
    "title": "Data Analysis",
    "section": "",
    "text": "Which columns are irrelevant or redundant?\nID, URL, ACTIVE_URLS, DUPLICATES, LAST_UPDATED TIMESTAMP are irrelevant or redundant columns. They are mostly used for internal tracking and don’t contribute to the actual analysis of jobs, industries, and occupations.\nWhy are we removing multiple versions of NAICS/SOC codes?\nThe dataset contains multiple versions of industry NAICS and Occupational SOC which can be risky to keep, as there is risk of duplications and inconsistent groupings.\nHow will this improve analysis?\nThis will improve the analysis by enhancing the efficiency of the data; by having smaller datasets it will be easier to process and run data. It will also improve consistency because by having only one version of the data the risk of duplication will be low.\n\n\ncolumns_to_drop = [\n'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'EXPIRED', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW','BODY',\n'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS',\n'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP',\n'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING',\n'MSA_OUTGOING', 'MSA_NAME_OUTGOING','MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4','NAICS4_NAME',\n'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME',\n'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'LOT_OCCUPATION_GROUP_NAME',\n'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP',\n'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME',\n'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME',\n'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'MODELED_EXPIRED', 'MODELED_DURATION', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME',\n'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LIGHTCAST_SECTORS',\n'LIGHTCAST_SECTORS_NAME'\n]\ndata.drop(columns=columns_to_drop, inplace=True)"
  },
  {
    "objectID": "data_analysis.html#handling-missing-values",
    "href": "data_analysis.html#handling-missing-values",
    "title": "Data Analysis",
    "section": "",
    "text": "Answer the question: How should missing values be handled?\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Industry) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n\n\n# Fill missing values\ndata[\"SALARY\"].fillna(data[\"SALARY\"].median(), inplace=True)\ndata[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\", inplace=True)\ndata[\"REMOTE_TYPE_NAME\"].fillna(\"None, inplace=True\")\n\ndata.rename(columns={'NAICS_2022_6_NAME': 'INDUSTRY'}, inplace=True)\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\1830881447.py:7: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\1830881447.py:8: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n\ndata.dropna(thresh=len(data) * 0.5, axis=1, inplace=True)\n\n# Visualize missing data\nimport matplotlib as mpl\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Set global font settings\nmpl.rcParams['font.family'] = 'Verdana'\nmpl.rcParams['font.size'] = 14\nmpl.rcParams['text.color'] = 'black'\nmpl.rcParams['axes.labelcolor'] = 'black'\nmpl.rcParams['xtick.color'] = 'black'\nmpl.rcParams['ytick.color'] = 'black'\n\n# Define custom green-to-red colormap\ncustom_cmap = LinearSegmentedColormap.from_list(\n    'custom_green_red', ['#B14E53', '#78C2AD'], N=256\n)\n\n# Create the heatmap\nfig = plt.figure(figsize=(10, 6))\nax = msno.heatmap(data, cmap=custom_cmap)\n\n# Set the title\nplt.title(\"Missing Values Heatmap\", fontsize=18, fontweight='bold')\n\nplt.show()\nplt.savefig(\"figures/missing_values.png\")\n\n&lt;Figure size 960x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;\n\n\nThe heatmap shows a few missing values in the dataset. In this dataset most fields cluster near 1. The value 1 (dark blue) means the two columns have missing values together. 0.0 value (white) suggest there is no relationship."
  },
  {
    "objectID": "data_analysis.html#remove-duplicates",
    "href": "data_analysis.html#remove-duplicates",
    "title": "Data Analysis",
    "section": "",
    "text": "data = data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
  },
  {
    "objectID": "data_analysis.html#job-postings-by-industry",
    "href": "data_analysis.html#job-postings-by-industry",
    "title": "Data Analysis",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Compute posting count per industry\ndata[\"posting_count\"] = data[\"ID\"].groupby(data[\"INDUSTRY\"]).transform(\"count\")\n\n# Summarize and sort top 25 industries\nindustry_summary = data.groupby(\"INDUSTRY\")[\"posting_count\"].first().sort_values(ascending=False).head(25)\n\n# Plot\nplt.figure(figsize=(12, 10))\nsns.barplot(\n    x=industry_summary.values,\n    y=industry_summary.index,\n    orient='h',\n    color='#6CC3D5'\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Top 25 Job Postings by Industry\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Number of Job Postings\", fontsize=14)\nplt.ylabel(\"Industry\", fontsize=14)\n\nplt.tight_layout()\nplt.show()\nplt.savefig(\"figures/top_postings.png\")\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "data_analysis.html#salary-distribution-by-industry",
    "href": "data_analysis.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Calculate average industry salary\ndata[\"AVERAGE_INDUSTRY_SALARY\"] = data[\"SALARY\"].groupby(data[\"INDUSTRY\"]).transform(\"mean\").round()\n\n# Get top 40 industries by average salary\ntop_40_industries = data.groupby(\"INDUSTRY\")[\"AVERAGE_INDUSTRY_SALARY\"].first().sort_values(ascending=False).head(40).index\nfiltered_data = data[data[\"INDUSTRY\"].isin(top_40_industries)]\n\n# Create figure with taller height\nplt.figure(figsize=(20, 14))  # Increased height from 10 to 14\n\n# Create boxplot with custom color\nsns.boxplot(\n    data=filtered_data,\n    x=\"INDUSTRY\",\n    y=\"SALARY\",\n    order=top_40_industries,\n    color='#F3969A'  # Custom box color\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Salary Distribution by Industry (Top 40 by Average Salary)\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Industry\", fontsize=14)\nplt.ylabel(\"Salary\", fontsize=14)\n\n# Rotate x-tick labels for readability\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\nplt.savefig(\"figures/salary_dist.png\")\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "data_analysis.html#remote-vs.-on-site-jobs",
    "href": "data_analysis.html#remote-vs.-on-site-jobs",
    "title": "Data Analysis",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Clean and group remote types\nremote_grouped = data[\"REMOTE_TYPE_NAME\"].fillna(\"Onsite\").replace({\n    \"[None]\": \"Onsite\", \n    \"Not Remote\": \"Onsite\",\n    \"None\": \"Onsite\"\n})\n\n# Count values\nremote_counts = remote_grouped.value_counts()\n\n# Define colors matching labels (make sure the order matches remote_counts.index)\ncolor_map = {\n    \"Onsite\": \"#297C8A\",\n    \"Hybrid Remote\": \"#78C2AD\",\n    \"Remote\": \"#F3969A\"\n}\n\n# Get colors for the pie chart slices in the correct order, fallback to gray if missing\ncolors = [color_map.get(label, \"#cccccc\") for label in remote_counts.index]\n\n# Plot pie chart\nplt.figure(figsize=(8, 8))\nwedges, texts, autotexts = plt.pie(\n    remote_counts.values,\n    labels=remote_counts.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    textprops={'fontsize': 14, 'color': 'black'}\n)\n\n# Title with larger font\nplt.title(\"Remote vs. On-Site Jobs\", fontsize=18, fontweight='bold', pad=20)\n\n# Adjust autotext (percentage text) font size\nfor autotext in autotexts:\n    autotext.set_fontsize(14)\n\nplt.show()\nplt.savefig(\"figures/remote_onsite.png\")\n\n\n\n\n\n\n\n\n&lt;Figure size 672x480 with 0 Axes&gt;"
  },
  {
    "objectID": "data_analysis.html#importing-dataset-using-pandas",
    "href": "data_analysis.html#importing-dataset-using-pandas",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('data\\lightcast_job_postings.csv')\n\n&lt;&gt;:4: SyntaxWarning:\n\ninvalid escape sequence '\\l'\n\n&lt;&gt;:4: SyntaxWarning:\n\ninvalid escape sequence '\\l'\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\3126061157.py:4: SyntaxWarning:\n\ninvalid escape sequence '\\l'\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_5484\\3126061157.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False."
  },
  {
    "objectID": "data_analysis.html#removing-duplicates",
    "href": "data_analysis.html#removing-duplicates",
    "title": "Data Analysis",
    "section": "",
    "text": "data = data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
  },
  {
    "objectID": "data_analysis.html#why-these-visualizations-were-chosen",
    "href": "data_analysis.html#why-these-visualizations-were-chosen",
    "title": "Data Analysis",
    "section": "",
    "text": "Bar Chart: Job Postings by Industry\n\nMakes it easy to compare job postings across different industries.\n\nProvides a clear ranking that is simple to interpret.\n\nBoxplot: Salary Distribution by Industry\n\nShows medians, outliers, and summarizes salary distributions.\n\nAllows for comparisons between industries and helps detect salary variability.\n\nPie Chart: Job Location Types\n\nProvides a clear visual breakdown of remote versus on-site jobs within the dataset."
  },
  {
    "objectID": "data_analysis.html#key-insights-from-each-graph",
    "href": "data_analysis.html#key-insights-from-each-graph",
    "title": "Data Analysis",
    "section": "",
    "text": "Bar Chart: Top 25 Industries by Job-Posting Volume\n\nThe distribution is skewed, showing demand concentrated in technology and professional services.\n\nA large portion of “unclassified industry” job postings suggests many jobs are not mapped to any industry.\n\nBoxplot: Salary Distribution by Industry\n\nSalaries across the 40 industries skew high, with medians generally in the $120k–$170k range.\n\nIndustries with higher medians and greater dispersions include software/semiconductors and consulting.\n\nSeveral industries have wide IQRs and many upper outliers, while some have less variability, indicating standardized pay.\n\nPie Chart: Job Location Types\n\n17% of jobs are remote, 3.1% are hybrid, and 1.6% are not remote.\n\nA large number of job postings do not specify whether the job is remote or on-site."
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\nfiltered_df = df[[\"ID\", \"BODY\"]]\nfiltered_df = filtered_df.dropna()\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_29480\\4251640159.py:2: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n# Assuming job_descriptions is a list of text from job postings\ntop_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\", \"Docker\", \"AWS\"]\n\nskill_counts = {}\nfor skill in top_skills:\n    skill_counts[skill] = filtered_df[\"BODY\"].str.contains(skill, case=False, na=False).sum()\n\nskills_df_pd = pd.DataFrame(list(skill_counts.items()), columns=['Skill', 'Count'])\n\nprint(skills_df_pd)\nskills_df_pd.to_csv(\"data/skills_job_description.csv\", index=False)\n\n              Skill  Count\n0            Python  12429\n1               SQL  24315\n2  Machine Learning   4072\n3   Cloud Computing   1425\n4            Docker    713\n5               AWS  14913\n\n\n\nimport plotly.express as px\n\ntop_skills_fig = px.bar(\n    skills_df_pd,\n    x='Skill',\n    y='Count',\n    title='Bar Chart of Job Description Skill Occurence',\n    color_discrete_sequence=['#3D7C6A']  # Set bar color\n)\n\n# Update layout for fonts and sizes\ntop_skills_fig.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\n\ntop_skills_fig.show()\ntop_skills_fig.write_image(\"figures/top_skills.png\")\ntop_skills_fig.write_html(\"figures/top_skills.html\")\n\n                            \n                                            \n\n\n\nWhich skills should each member prioritize learning?\n\nBased on the self assessment rating of each member of the group, everyone should prioritize learning cloud computing.\nCloud Computing is gaining popularity as data is moving to the cloud. Most companies are using cloud services to have easy access to data globally and in real time.\n\n\n\nWhat courses or resources can help?\n\nThe resources and courses that can be helpful in learning cloud computing skills include:\n\nGoogle Cloud Fundamentals\nAWS Academy Cloud Foundations\nMicrosoft Learn - Azure Fundamentals\nAWS Certified Data Analytics – Specialty\nAzure Data Fundamentals (DP-900)\n\n\n\n\nHow can the team collaborate to bridge skill gaps?\n\nIdentify gaps that are related to the project needs and work on it as a group to learn from eachother.\nSplit tasks and divide work according to each memeber’s skill level.\nCross-train so everyone can learn from each other and develop understanding of cloud analytics tasks."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\nskills_data = {\n    \"Name\": [\"Ava\", \"Mahira\", \"Joshua\"],\n    \"Python\": [2, 3, 3],\n    \"SQL\": [2, 1, 4],\n    \"Machine Learning\": [1, 3, 2],\n    \"Cloud Computing\": [1, 1, 1]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nAva\n2\n2\n1\n1\n\n\nMahira\n3\n1\n3\n1\n\n\nJoshua\n3\n4\n2\n1"
  },
  {
    "objectID": "eda.html#team-skill-level-dataframe",
    "href": "eda.html#team-skill-level-dataframe",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\nskills_data = {\n    \"Name\": [\"Ava\", \"Mahira\", \"Joshua\"],\n    \"Python\": [2, 3, 3],\n    \"SQL\": [2, 1, 4],\n    \"Machine Learning\": [1, 3, 2],\n    \"Cloud Computing\": [1, 1, 1]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nAva\n2\n2\n1\n1\n\n\nMahira\n3\n1\n3\n1\n\n\nJoshua\n3\n4\n2\n1"
  },
  {
    "objectID": "eda.html#visualizing-skill-gaps-in-heatmpa-with-plotly",
    "href": "eda.html#visualizing-skill-gaps-in-heatmpa-with-plotly",
    "title": "Exploratory Data Analysis",
    "section": "Visualizing Skill Gaps in Heatmpa with Plotly",
    "text": "Visualizing Skill Gaps in Heatmpa with Plotly\n\nimport kaleido\nimport plotly.express as px\nfig = px.imshow(df_skills,\n labels=dict(x=\"Skill\", y=\"Team Member Name\", color=\"Skill Self Rating\"),\n title=\"Key IT Skill Rating Heatmap per Team Member\"\n)\nfig.update_layout(\n  title=dict(\n    text=\"Key IT Skill Rating Heatmap per Team Member\",\n    font=dict(size=24, family=\"Arial\", color=\"black\", weight=\"bold\")\n  ),\n  xaxis=dict(\n    title=dict(text=\"Skill\", font=dict(size=20, family=\"Arial\", color=\"black\", weight=\"bold\")),\n    tickangle=90,\n    tickfont=dict(size=10, family=\"Arial\", color=\"black\", weight=\"bold\"),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n  ),\n  yaxis=dict(\n    title=dict(text=\"Teammember Name\", font=dict(size=20, family=\"Arial\", color=\"black\", weight=\"bold\")),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n    gridcolor=\"lightgray\",\n    gridwidth=0.5\n  ),\n  font=dict(family=\"Arial\", size=16, color=\"black\"),\n  paper_bgcolor=\"#DCDCDC\",\n  showlegend=True,\n)\nfig.show()\nfig.write_image(\"figures/skill_heatmap.png\")\nfig.write_html(\"figures/skill_heatmap.html\")"
  },
  {
    "objectID": "eda.html#visualizing-skill-gaps-in-heatmap-with-plotly",
    "href": "eda.html#visualizing-skill-gaps-in-heatmap-with-plotly",
    "title": "Exploratory Data Analysis",
    "section": "Visualizing Skill Gaps in Heatmap with Plotly",
    "text": "Visualizing Skill Gaps in Heatmap with Plotly\n\nimport kaleido\nimport plotly.express as px\ncustom_colorscale = [\"#B14E53\", \"#78C2AD\", ]\nfig = px.imshow(df_skills,\n labels=dict(x=\"Skill\", y=\"Team Member Name\", color=\"Skill Self Rating\"),\n title=\"Key IT Skill Rating Heatmap per Team Member\",\n    color_continuous_scale=custom_colorscale\n)\nfig.update_layout(\n  title=dict(\n    text=\"Key IT Skill Rating Heatmap per Team Member\",\n    font=dict(size=18, family=\"Verdana\", color=\"black\", weight=\"bold\")\n  ),\n  xaxis=dict(\n    title=dict(text=\"Skill\", font=dict(size=20, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    tickangle=90,\n    tickfont=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\"),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n  ),\n  yaxis=dict(\n    title=dict(text=\"Teammember Name\", font=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n    gridcolor=\"white\",\n    gridwidth=0.5\n  ),\n  font=dict(family=\"Verdana\", size=14, color=\"black\"),\n  paper_bgcolor=\"white\",\n  showlegend=True,\n)\nfig.show()\nfig.write_image(\"figures/skill_heatmap.png\")\nfig.write_html(\"figures/skill_heatmap.html\")"
  }
]