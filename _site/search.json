[
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "import pandas as pd\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\nfiltered_df = df[[\"ID\", \"BODY\"]]\nfiltered_df = filtered_df.dropna()\n\n\n# Assuming job_descriptions is a list of text from job postings\ntop_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\", \"Docker\", \"AWS\"]\n\nskill_counts = {}\nfor skill in top_skills:\n    skill_counts[skill] = filtered_df[\"BODY\"].str.contains(skill, case=False, na=False).sum()\n\nskills_df_pd = pd.DataFrame(list(skill_counts.items()), columns=['Skill', 'Count'])\n\nprint(skills_df_pd)\nskills_df_pd.to_csv(\"data/skills_job_description.csv\", index=False)\n\n\nimport plotly.express as px\n\ntop_skills_fig = px.bar(\n    skills_df_pd,\n    x='Skill',\n    y='Count',\n    title='Bar Chart of Job Description Skill Occurence',\n    color_discrete_sequence=['#3D7C6A']  # Set bar color\n)\n\n# Update layout for fonts and sizes\ntop_skills_fig.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\n\ntop_skills_fig.show()\ntop_skills_fig.write_image(\"./figures/top_skills.png\")\ntop_skills_fig.write_html(\"./figures/top_skills.html\")\n\n\n\nWhich skills should each member prioritize learning?\n\nBased on the self assessment rating of each member of the group, everyone should prioritize learning cloud computing.\nCloud Computing is gaining popularity as data is moving to the cloud. Most companies are using cloud services to have easy access to data globally and in real time.\n\n\n\nWhat courses or resources can help?\n\nThe resources and courses that can be helpful in learning cloud computing skills include:\n\nGoogle Cloud Fundamentals\nAWS Academy Cloud Foundations\nMicrosoft Learn - Azure Fundamentals\nAWS Certified Data Analytics – Specialty\nAzure Data Fundamentals (DP-900)\n\n\n\n\nHow can the team collaborate to bridge skill gaps?\n\nIdentify gaps that are related to the project needs and work on it as a group to learn from eachother.\nSplit tasks and divide work according to each memeber’s skill level.\nCross-train so everyone can learn from each other and develop understanding of cloud analytics tasks."
  },
  {
    "objectID": "ml_methods.html",
    "href": "ml_methods.html",
    "title": "ML Methods",
    "section": "",
    "text": "import os\n# Set JAVA_HOME\nos.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk-17'  # Update to your exact path\nimport pyspark\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\n# Stop any existing Spark sessions\nSparkSession.getActiveSession() and SparkSession.getActiveSession().stop()\n# Initialize Spark Session with explicit local master\nspark = SparkSession.builder \\\n    .appName(\"LightcastData\") \\\n    .master(\"local[*]\") \\\n    .config(\"spark.driver.host\", \"localhost\") \\\n    .getOrCreate()\n# Load Data\ndf = spark.read \\\n    .option(\"header\", \"true\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .option(\"multiLine\", \"true\") \\\n    .option(\"escape\", \"\\\"\") \\\n    .csv(\"data/lightcast_job_postings.csv\")\n# Show Schema and Sample Data\n# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n# df.printSchema()\n# df.show(5)\n\n\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator\nfrom pyspark.ml.stat import Correlation\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Filter for valid salary data\ndf_clean = df.filter(\n    (F.col(\"SALARY\").isNotNull()) & \n    (F.col(\"SALARY\") &gt; 0) &\n    (F.col(\"STATE_NAME\").isNotNull()) &\n    (F.col(\"TITLE_NAME\").isNotNull())\n)\n\nprint(f\"Original dataset size: {df.count():,}\")\nprint(f\"Cleaned dataset size: {df_clean.count():,}\")\n\n# Calculate salary statistics\nsalary_stats = df_clean.select(\n    F.mean(\"SALARY\").alias(\"mean_salary\"),\n    F.expr(\"percentile_approx(SALARY, 0.5)\").alias(\"median_salary\"),\n    F.stddev(\"SALARY\").alias(\"std_salary\"),\n    F.min(\"SALARY\").alias(\"min_salary\"),\n    F.max(\"SALARY\").alias(\"max_salary\")\n).collect()[0]\n\nprint(f\"\\nSalary Statistics:\")\nprint(f\"  Mean: ${salary_stats['mean_salary']:,.2f}\")\nprint(f\"  Median: ${salary_stats['median_salary']:,.2f}\")\nprint(f\"  Std Dev: ${salary_stats['std_salary']:,.2f}\")\nprint(f\"  Min: ${salary_stats['min_salary']:,.2f}\")\nprint(f\"  Max: ${salary_stats['max_salary']:,.2f}\")\n\n# Create binary classification target (above average = 1, below average = 0)\navg_salary = salary_stats['mean_salary']\ndf_clean = df_clean.withColumn(\n    \"ABOVE_AVERAGE_SALARY\",\n    F.when(F.col(\"SALARY\") &gt; avg_salary, 1).otherwise(0)\n)\n\n\n# Handle SKILLS_NAME - it may contain arrays or null values\n# Extract first skill or mark as \"No Skills Listed\"\ndf_clean = df_clean.withColumn(\n    \"PRIMARY_SKILL\",\n    F.when(\n        F.col(\"SKILLS_NAME\").isNotNull(),\n        F.split(F.regexp_replace(F.col(\"SKILLS_NAME\"), r'[\\[\\]\"\\n]', ''), \",\").getItem(0)\n    ).otherwise(\"No Skills Listed\")\n)\n\n# Select features and target, and clean empty strings\nfeatures_df = df_clean.select(\n    \"STATE_NAME\",\n    \"TITLE_NAME\", \n    \"PRIMARY_SKILL\",\n    \"SALARY\",\n    \"ABOVE_AVERAGE_SALARY\"\n).withColumn(\n    \"STATE_NAME\",\n    F.when((F.col(\"STATE_NAME\").isNull()) | (F.trim(F.col(\"STATE_NAME\")) == \"\"), \"Unknown\")\n     .otherwise(F.trim(F.col(\"STATE_NAME\")))\n).withColumn(\n    \"TITLE_NAME\",\n    F.when((F.col(\"TITLE_NAME\").isNull()) | (F.trim(F.col(\"TITLE_NAME\")) == \"\"), \"Unknown\")\n     .otherwise(F.trim(F.col(\"TITLE_NAME\")))\n).withColumn(\n    \"PRIMARY_SKILL\",\n    F.when((F.col(\"PRIMARY_SKILL\").isNull()) | (F.trim(F.col(\"PRIMARY_SKILL\")) == \"\"), \"No Skills Listed\")\n     .otherwise(F.trim(F.col(\"PRIMARY_SKILL\")))\n)\n\n# Show feature distribution\nprint(\"\\nTop 10 States by Job Postings:\")\nfeatures_df.groupBy(\"STATE_NAME\").count().orderBy(F.desc(\"count\")).show(10, truncate=False)\n\nprint(\"\\nTop 10 Job Titles by Frequency:\")\nfeatures_df.groupBy(\"TITLE_NAME\").count().orderBy(F.desc(\"count\")).show(10, truncate=False)\n\nprint(\"\\nTop 10 Skills by Frequency:\")\nfeatures_df.groupBy(\"PRIMARY_SKILL\").count().orderBy(F.desc(\"count\")).show(10, truncate=False)\n\n\n# String indexing for categorical variables\nstate_indexer = StringIndexer(inputCol=\"STATE_NAME\", outputCol=\"STATE_INDEX\", handleInvalid=\"keep\")\ntitle_indexer = StringIndexer(inputCol=\"TITLE_NAME\", outputCol=\"TITLE_INDEX\", handleInvalid=\"keep\")\nskill_indexer = StringIndexer(inputCol=\"PRIMARY_SKILL\", outputCol=\"SKILL_INDEX\", handleInvalid=\"keep\")\n\n# One-hot encoding\nstate_encoder = OneHotEncoder(inputCol=\"STATE_INDEX\", outputCol=\"STATE_VEC\")\ntitle_encoder = OneHotEncoder(inputCol=\"TITLE_INDEX\", outputCol=\"TITLE_VEC\")\nskill_encoder = OneHotEncoder(inputCol=\"SKILL_INDEX\", outputCol=\"SKILL_VEC\")\n\n# Assemble features\nassembler = VectorAssembler(\n    inputCols=[\"STATE_VEC\", \"TITLE_VEC\", \"SKILL_VEC\"],\n    outputCol=\"features\"\n)\n\n# Split data (80% train, 20% test)\ntrain_data, test_data = features_df.randomSplit([0.8, 0.2], seed=42)\n\nprint(f\"Training set size: {train_data.count():,}\")\nprint(f\"Test set size: {test_data.count():,}\")\n\n\n# Linear Regression model\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"SALARY\", maxIter=100, regParam=0.1)\n\n# Create pipeline\nlr_pipeline = Pipeline(stages=[\n    state_indexer, title_indexer, skill_indexer,\n    state_encoder, title_encoder, skill_encoder,\n    assembler, lr\n])\n\n# Train the model\nlr_model = lr_pipeline.fit(train_data)\n\n# Make predictions\nlr_predictions = lr_model.transform(test_data)\n\n# Evaluate the model\nevaluator_rmse = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"rmse\")\nevaluator_r2 = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"r2\")\nevaluator_mae = RegressionEvaluator(labelCol=\"SALARY\", predictionCol=\"prediction\", metricName=\"mae\")\n\nrmse = evaluator_rmse.evaluate(lr_predictions)\nr2 = evaluator_r2.evaluate(lr_predictions)\nmae = evaluator_mae.evaluate(lr_predictions)\n\nprint(f\"\\nLinear Regression Model Performance:\")\nprint(f\"  RMSE: ${rmse:,.2f}\")\nprint(f\"  R² Score: {r2:.4f}\")\nprint(f\"  MAE: ${mae:,.2f}\")\n\n# Show sample predictions\nprint(\"\\nSample Predictions:\")\nlr_predictions.select(\"STATE_NAME\", \"TITLE_NAME\", \"PRIMARY_SKILL\", \"SALARY\", \"prediction\").show(10, truncate=50)\n\n\n# Logistic Regression model\nlog_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"ABOVE_AVERAGE_SALARY\", maxIter=100)\n\n# Create pipeline\nlog_pipeline = Pipeline(stages=[\n    state_indexer, title_indexer, skill_indexer,\n    state_encoder, title_encoder, skill_encoder,\n    assembler, log_reg\n])\n\n# Train the model\nlog_model = log_pipeline.fit(train_data)\n\n# Make predictions\nlog_predictions = log_model.transform(test_data)\n\n# Evaluate classification model\nauc_evaluator = BinaryClassificationEvaluator(labelCol=\"ABOVE_AVERAGE_SALARY\", metricName=\"areaUnderROC\")\nauc = auc_evaluator.evaluate(log_predictions)\n\n# Calculate accuracy\naccuracy = log_predictions.filter(\n    F.col(\"ABOVE_AVERAGE_SALARY\") == F.col(\"prediction\")\n).count() / log_predictions.count()\n\nprint(f\"\\nLogistic Regression Model Performance:\")\nprint(f\"  AUC-ROC: {auc:.4f}\")\nprint(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n\n# Confusion Matrix\nprint(\"\\nConfusion Matrix:\")\nconfusion_matrix = log_predictions.groupBy(\"ABOVE_AVERAGE_SALARY\", \"prediction\").count()\nconfusion_matrix.orderBy(\"ABOVE_AVERAGE_SALARY\", \"prediction\").show()\n\n\n# Extract the trained linear regression model\ntrained_lr = lr_model.stages[-1]\ncoefficients = trained_lr.coefficients\nintercept = trained_lr.intercept\n\nprint(f\"Model Intercept: ${intercept:,.2f}\")\nprint(f\"Number of features: {len(coefficients)}\")\nprint(f\"Sum of coefficients: {sum(coefficients):,.2f}\")\n\n\nimport kaleido\npred_data = lr_predictions.select(\"SALARY\", \"prediction\", \"STATE_NAME\", \"TITLE_NAME\").limit(1000).collect()\npred_sample = pd.DataFrame(pred_data, columns=[\"SALARY\", \"prediction\", \"STATE_NAME\", \"TITLE_NAME\"])\n\nfig1 = px.scatter(\n    pred_sample, \n    x=\"SALARY\", \n    y=\"prediction\",\n    title=\"Actual vs Predicted Salary (Linear Regression)\",\n    labels={\"SALARY\": \"Actual Salary ($)\", \"prediction\": \"Predicted Salary ($)\"},\n    opacity=0.6,\n    hover_data=[\"STATE_NAME\", \"TITLE_NAME\"],\n    color_discrete_sequence=['#78C2AD']\n)\nfig1.add_trace(go.Scatter(\n    x=[pred_sample[\"SALARY\"].min(), pred_sample[\"SALARY\"].max()],\n    y=[pred_sample[\"SALARY\"].min(), pred_sample[\"SALARY\"].max()],\n    mode='lines',\n    name='Perfect Prediction',\n    line=dict(color='red', dash='dash')\n))\nfig1.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\nfig1.show()\nfig1.write_image(\"figures/regressionscatter.png\")\n\n\nstate_salary_data = df_clean.groupBy(\"STATE_NAME\").agg(\n    F.mean(\"SALARY\").alias(\"avg_salary\"),\n    F.count(\"SALARY\").alias(\"job_count\")\n).orderBy(F.desc(\"avg_salary\")).limit(10).collect()\nstate_salary = pd.DataFrame(state_salary_data, columns=[\"STATE_NAME\", \"avg_salary\", \"job_count\"])\n\nfig2 = px.bar(\n    state_salary,\n    x=\"STATE_NAME\",\n    y=\"avg_salary\",\n    title=\"Top 10 States by Average Salary\",\n    labels={\"STATE_NAME\": \"State\", \"avg_salary\": \"Average Salary ($)\"},\n    color=\"avg_salary\",\n    text=\"job_count\",\n    color_continuous_scale=px.colors.sequential.Mint\n)\nfig2.update_traces(texttemplate='Jobs: %{text}', textposition='outside')\nfig2.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\nfig2.show()\nfig2.write_image(\"figures/top10statesbarplot.png\")\n\n\nsalary_class_data = log_predictions.groupBy(\"ABOVE_AVERAGE_SALARY\").count().collect()\nsalary_class = pd.DataFrame(salary_class_data, columns=[\"ABOVE_AVERAGE_SALARY\", \"count\"])\nsalary_class[\"Category\"] = salary_class[\"ABOVE_AVERAGE_SALARY\"].map({0: \"Below Average\", 1: \"Above Average\"})\n\nfig3 = px.pie(\n    salary_class,\n    values=\"count\",\n    names=\"Category\",\n    title=\"Distribution of Above/Below Average Salaries\",\n    color_discrete_sequence=[\"#78C2AD\", \"#F3969A\"]\n)\nfig3.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\nfig3.show()\nfig3.write_image(\"figures/salaryaveragepiechart.png\")\n\n\ntitle_salary_data = df_clean.groupBy(\"TITLE_NAME\").agg(\n    F.mean(\"SALARY\").alias(\"avg_salary\"),\n    F.count(\"SALARY\").alias(\"count\")\n).filter(F.col(\"count\") &gt; 5).orderBy(F.desc(\"avg_salary\")).limit(15).collect()\ntitle_salary = pd.DataFrame(title_salary_data, columns=[\"TITLE_NAME\", \"avg_salary\", \"count\"])\n\nfig4 = px.bar(\n    title_salary,\n    x=\"avg_salary\",\n    y=\"TITLE_NAME\",\n    orientation='h',\n    title=\"Top 15 Job Titles by Average Salary (min 5 postings)\",\n    labels={\"TITLE_NAME\": \"Job Title\", \"avg_salary\": \"Average Salary ($)\"},\n    color=\"avg_salary\",\n    color_continuous_scale=px.colors.sequential.Mint\n)\nfig4.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\nfig4.show()\nfig4.write_image(\"figures/Top15Bar.png\")\n\npredictions_data = lr_predictions.select(\n    \"STATE_NAME\", \"TITLE_NAME\", \"PRIMARY_SKILL\", \n    \"SALARY\", \"prediction\", \"ABOVE_AVERAGE_SALARY\"\n).limit(10000).collect()  \n\npredictions_pdf = pd.DataFrame(\n    predictions_data, \n    columns=[\"STATE_NAME\", \"TITLE_NAME\", \"PRIMARY_SKILL\", \"SALARY\", \"prediction\", \"ABOVE_AVERAGE_SALARY\"]\n)\npredictions_pdf.to_csv(\"output/salary_predictions.csv\", index=False)\nprint(f\"Results saved to: output/salary_predictions.csv ({len(predictions_pdf):,} rows)\")\n\n   \n\nActual vs Predicted Salaries (Linear Regression)\nThe scatter plot above compares actual versus predicted salaries generated by a linear regression model. Each point represents an observation, while the red dashed line indicates a perfect prediction—where actual and predicted salaries would be equal.\nFrom the visualization, we can observe that the majority of predictions cluster near the perfect-fit line, suggesting that the model captures the general salary trend reasonably well. However, there is noticeable spread at higher salary levels, indicating that the model tends to underpredict high salaries and overpredict some lower ones, reflecting moderate accuracy but potential room for improvement in capturing extreme salary values.\n\n\nTop 10 States by Average Salary\nThe bar chart above highlights the top 10 U.S. states by average salary in the dataset. Connecticut leads with the highest average salary, followed closely by Vermont, New Jersey, and Washington. While these states offer strong compensation levels, the number of available jobs varies significantly—from as few as 101 in Vermont to nearly 4,000 in California.\nOverall, the visualization suggests that smaller states such as Connecticut and Vermont offer higher average pay but fewer total job opportunities, whereas larger labor markets like California and Virginia have more positions but slightly lower average salaries. This pattern indicates a tradeoff between salary level and job volume across states.\n\n\nDistribution of Above/Below Average Salaries\nThe pie chart above displays the distribution of salaries above and below the overall average based on the binary classification assigned. Approximately 51.4% of roles fall below the average salary, while 48.6% are above average, indicating a nearly even split.\nThis balance suggests that salaries across the dataset are relatively symmetrically distributed, with only a slight tilt toward lower-paying positions. The small difference between the two segments highlights a moderately balanced job market, where compensation levels are fairly evenly dispersed around the mean.\n\n\nTop 15 Job Titles by Average Salaries\nThe horizontal bar chart above highlights the top 15 job titles ranked by average salary among roles with at least five postings. The results show that Distinguished Architects and Enterprise Services Managers command the highest average salaries, both exceeding $270K annually. Other top earners include Directors of Enterprise Architecture and Advisory Solution Consultants, which also sit well above the $200K threshold.\nOverall, the visualization indicates that executive-level and architecture-focused roles tend to yield the highest compensation, reflecting the premium placed on leadership, system design, and strategic technical expertise in today’s data and cloud-driven job market.\n\nimport pandas as pd\nimport plotly.express as px\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np\n\n# Load data\ndf = pd.read_csv(\"lightcast_job_postings.csv\")\n\n# Keep relevant columns\ncols = ['STATE_NAME', 'TITLE_NAME', 'SPECIALIZED_SKILLS_NAME', 'SALARY_FROM', 'SALARY_TO']\ndf = df[cols].dropna(subset=['SALARY_FROM', 'SALARY_TO'])\n\n# Compute average salary\ndf['AVERAGE_SALARY'] = (df['SALARY_FROM'] + df['SALARY_TO']) / 2\n\n# Create AI classification flag based on job title or skills\nai_keywords = ['AI', 'Artificial Intelligence', 'Machine Learning', 'ML', 'Deep Learning', \n               'Data Scientist', 'Neural', 'Computer Vision', 'NLP']\n\ndef classify_ai(row):\n    text = f\"{row['TITLE_NAME']} {row['SPECIALIZED_SKILLS_NAME']}\".upper()\n    return 'AI' if any(word in text for word in ai_keywords) else 'Non-AI'\n\ndf['AI_CLASSIFICATION'] = df.apply(classify_ai, axis=1)\n\n# Aggregate salary by region and AI classification\nsalary_summary = (\n    df.groupby(['STATE_NAME', 'AI_CLASSIFICATION'])\n      .agg(MEAN_SALARY=('AVERAGE_SALARY', 'mean'),\n           COUNT=('AVERAGE_SALARY', 'count'))\n      .reset_index()\n)\n\n# Plot salary comparison by state\nfig = px.bar(\n    salary_summary,\n    x='STATE_NAME',\n    y='MEAN_SALARY',\n    color='AI_CLASSIFICATION',\n    barmode='group',\n    text_auto='.2s',\n    color_discrete_map={'AI': \"#714E50\", 'Non-AI': '#297C8A'},\n    title=\"Average Salary Comparison by State and AI Classification\"\n)\n\nfig.update_layout(\n    xaxis_title=\"State\",\n    yaxis_title=\"Average Salary ($)\",\n    legend_title=\"Job Type\",\n    template=\"plotly_white\",\n    font=dict(family=\"Roboto\", size=14),\n    xaxis={'categoryorder': 'total descending'}\n)\n\nfig.show()\nfig.write_image(\"figures/statesalary.png\")\n\n# Regression model – Predict salary using AI classification and state\nle_state = LabelEncoder()\nle_ai = LabelEncoder()\n\ndf['STATE_ENCODED'] = le_state.fit_transform(df['STATE_NAME'])\ndf['AI_FLAG'] = le_ai.fit_transform(df['AI_CLASSIFICATION'])\n\nX = df[['STATE_ENCODED', 'AI_FLAG']]\ny = df['AVERAGE_SALARY']\n\nmodel = LinearRegression()\nmodel.fit(X, y)\ny_pred = model.predict(X)\n\n# 8Model evaluation\nr2 = r2_score(y, y_pred)\nrmse = np.sqrt(mean_squared_error(y, y_pred))\n\nprint(\"R² Score:\", round(r2, 3))\nprint(\"RMSE:\", round(rmse, 2))\n\n\nThe bar chart shown above compares average salaries across U.S. states and shows jobs split between AI and non-AI roles. By looking at the graph we can see that AI-related jobs have higher average salaries than non-AI jobs. Some States like New Jersey, Connecticut, Montana and Arkansas have the highest salaries for AI roles. By looking at the overall data we can determine that AI expertise can boost earning potential nationwide.\n\n# Import libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans\nimport plotly.graph_objects as go\n\n# --------------------------------------------------\n# 1. Load and clean the dataset\n# --------------------------------------------------\ndf_clean = pd.read_csv(\"lightcast_job_postings.csv\")  \n\n# Convert salary-related columns to numeric (replace with actual salary column name)\n# Try to find which column represents salary (SALARY, SALARY_FROM, AVERAGE_SALARY, etc.)\nsalary_cols = [col for col in df_clean.columns if 'salary' in col.lower()]\nprint(\"Salary-related columns found:\", salary_cols)\n\n# Choose one salary column\nsalary_col = salary_cols[0]  # use the first match (adjust manually if needed)\n\ndf_clean[salary_col] = pd.to_numeric(df_clean[salary_col], errors='coerce')\n\n# Drop rows where salary or state name is missing\ndf_clean = df_clean.dropna(subset=[salary_col, 'STATE_NAME'])\n\n# --------------------------------------------------\n# 2. Compute average salary per state\n# --------------------------------------------------\nstate_salary = df_clean.groupby('STATE_NAME')[salary_col].mean().reset_index()\nstate_salary.rename(columns={salary_col: 'AVERAGE_SALARY'}, inplace=True)\n\n# --------------------------------------------------\n# 3. Prepare data for clustering\n# --------------------------------------------------\nX = state_salary[['AVERAGE_SALARY']].copy()\n# Add a numeric index for plotting purposes\nstate_salary['STATE_INDEX'] = np.arange(len(state_salary))\n\n# --------------------------------------------------\n# 4. Run KMeans clustering\n# --------------------------------------------------\nkmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\nstate_salary['CLUSTER'] = kmeans.fit_predict(X)\ncentroids = kmeans.cluster_centers_\n\n# --------------------------------------------------\n# 5. Visualization with Plotly\n# --------------------------------------------------\ncolors = ['#3D7C6A', '#B14E53', '#297C8A']\n\nfig = go.Figure()\n\n# Add points for each cluster\nfor i in range(3):\n    cluster_data = state_salary[state_salary['CLUSTER'] == i]\n    fig.add_trace(go.Scatter(\n        x=cluster_data['STATE_INDEX'],\n        y=cluster_data['AVERAGE_SALARY'],\n        mode='markers+text',\n        name=f'Cluster {i+1}',\n        text=cluster_data['STATE_NAME'],\n        textposition=\"top center\",\n        marker=dict(color=colors[i], size=10, opacity=0.7),\n        hovertemplate=(\n            'State: %{text}&lt;br&gt;'\n            'Average Salary: $%{y:,.0f}&lt;br&gt;'\n            'Cluster: ' + str(i+1) + '&lt;extra&gt;&lt;/extra&gt;'\n        )\n    ))\n\n# Add centroid marker\nfig.add_trace(go.Scatter(\n    x=np.arange(3),\n    y=centroids.flatten(),\n    mode='markers',\n    name='Centroids',\n    marker=dict(color='black', size=15, symbol='x', line=dict(width=2)),\n    hovertemplate='Centroid Salary: $%{y:,.0f}&lt;extra&gt;&lt;/extra&gt;'\n))\n\n# --------------------------------------------------\n# 6. Style the layout\n# --------------------------------------------------\nfig.update_layout(\n    title=dict(text='KMeans Clustering by Average Salary per State', font=dict(size=18)),\n    xaxis=dict(title='State Index (for plotting only)', tickfont=dict(size=12)),\n    yaxis=dict(title='Average Salary ($)', tickfont=dict(size=12)),\n    font=dict(family='Verdana', size=14),\n    plot_bgcolor='#f8f9fa',\n    paper_bgcolor='white',\n    hovermode='closest'\n)\n\nfig.show()\nfig.write_image(\"figures/kmeans.png\")\n\n\nThe KMeans clustering graph groups the U.S. States into three clusters based on their average salaries. On the y-axis we have average salary level and on the x-axis we have the State index (used for spacing). Each dot shown on the graph represents a State.\nThe three clusters illustrate which states have higher-than-average, mid-range, and lower average salaries.\n\nHigh paying cluster (Cluster 1-Green): This cluster includes States like NJ, MA,CT, and CA which have the highest average salaries and tend to have high living costs and major economic hubs.\nMid salary cluster (Cluster 2-Red): This cluster includes States like OH,FL, LA and NH where salaries are moderate and reflects a balanced labor market.\nLower salary cluster (Cluster 3-Teal): This cluster includes States like NV, NM, ND and WV who have low living costs and small urban centers.\n\nThe centroids the black Xs on the graph summarize the average salary levels of each cluster. The top centroid shows high income states. The middle centroid shows average income states and the bottom centroid shows low income states. These centroids helps us to interpret and visualize income-level groupings across different U.S. states."
  },
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('./data/lightcast_job_postings.csv')\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_18744\\4222856436.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\n\n\n\n\nWhich columns are irrelevant or redundant?\nID, URL, ACTIVE_URLS, DUPLICATES, LAST_UPDATED TIMESTAMP are irrelevant or redundant columns. They are mostly used for internal tracking and don’t contribute to the actual analysis of jobs, industries, and occupations.\nWhy are we removing multiple versions of NAICS/SOC codes?\nThe dataset contains multiple versions of industry NAICS and Occupational SOC which can be risky to keep, as there is risk of duplications and inconsistent groupings.\nHow will this improve analysis?\nThis will improve the analysis by enhancing the efficiency of the data; by having smaller datasets it will be easier to process and run data. It will also improve consistency because by having only one version of the data the risk of duplication will be low.\n\n\ncolumns_to_drop = [\n'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'EXPIRED', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW','BODY',\n'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS',\n'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP',\n'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING',\n'MSA_OUTGOING', 'MSA_NAME_OUTGOING','MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4','NAICS4_NAME',\n'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME',\n'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'LOT_OCCUPATION_GROUP_NAME',\n'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP',\n'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME',\n'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME',\n'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'MODELED_EXPIRED', 'MODELED_DURATION', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME',\n'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LIGHTCAST_SECTORS',\n'LIGHTCAST_SECTORS_NAME'\n]\ndata.drop(columns=columns_to_drop, inplace=True)\n\n\n\n\n\nAnswer the question: How should missing values be handled?\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Industry) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n\n\n# Fill missing values\ndata[\"SALARY\"].fillna(data[\"SALARY\"].median(), inplace=True)\ndata[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\", inplace=True)\ndata[\"REMOTE_TYPE_NAME\"].fillna(\"None, inplace=True\")\n\ndata.rename(columns={'NAICS_2022_6_NAME': 'INDUSTRY'}, inplace=True)\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_18744\\1830881447.py:7: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_18744\\1830881447.py:8: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n\ndata.dropna(thresh=len(data) * 0.5, axis=1, inplace=True)\n\n# Visualize missing data\nimport matplotlib as mpl\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Set global font settings\nmpl.rcParams['font.family'] = 'Verdana'\nmpl.rcParams['font.size'] = 14\nmpl.rcParams['text.color'] = 'black'\nmpl.rcParams['axes.labelcolor'] = 'black'\nmpl.rcParams['xtick.color'] = 'black'\nmpl.rcParams['ytick.color'] = 'black'\n\n# Define custom green-to-red colormap\ncustom_cmap = LinearSegmentedColormap.from_list(\n    'custom_green_red', ['#B14E53', '#78C2AD'], N=256\n)\n\n# Create the heatmap\nfig = plt.figure(figsize=(10, 6))\nax = msno.heatmap(data, cmap=custom_cmap)\n\n# Set the title\nplt.title(\"Missing Values Heatmap\", fontsize=18, fontweight='bold')\n\nplt.savefig(\"figures/missing_values.png\")\nplt.show()\n\n&lt;Figure size 960x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nThe heatmap shows a few missing values in the dataset. In this dataset most fields cluster near 1. The value 1 (dark blue) means the two columns have missing values together. 0.0 value (white) suggest there is no relationship.\n\n\n\n\ndata = data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Compute posting count per industry\ndata[\"posting_count\"] = data[\"ID\"].groupby(data[\"INDUSTRY\"]).transform(\"count\")\n\n# Summarize and sort top 25 industries\nindustry_summary = data.groupby(\"INDUSTRY\")[\"posting_count\"].first().sort_values(ascending=False).head(25)\n\n# Plot\nplt.figure(figsize=(12, 10))\nsns.barplot(\n    x=industry_summary.values,\n    y=industry_summary.index,\n    orient='h',\n    color='#6CC3D5'\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Top 25 Job Postings by Industry\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Number of Job Postings\", fontsize=14)\nplt.ylabel(\"Industry\", fontsize=14)\n\nplt.tight_layout()\n\nplt.savefig(\"figures/top_postings.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Calculate average industry salary\ndata[\"AVERAGE_INDUSTRY_SALARY\"] = data[\"SALARY\"].groupby(data[\"INDUSTRY\"]).transform(\"mean\").round()\n\n# Get top 40 industries by average salary\ntop_40_industries = data.groupby(\"INDUSTRY\")[\"AVERAGE_INDUSTRY_SALARY\"].first().sort_values(ascending=False).head(40).index\nfiltered_data = data[data[\"INDUSTRY\"].isin(top_40_industries)]\n\n# Create figure with taller height\nplt.figure(figsize=(20, 14))  # Increased height from 10 to 14\n\n# Create boxplot with custom color\nsns.boxplot(\n    data=filtered_data,\n    x=\"INDUSTRY\",\n    y=\"SALARY\",\n    order=top_40_industries,\n    color='#F3969A'  # Custom box color\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Salary Distribution by Industry (Top 40 by Average Salary)\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Industry\", fontsize=14)\nplt.ylabel(\"Salary\", fontsize=14)\n\n# Rotate x-tick labels for readability\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\n\n\nplt.savefig(\"figures/salary_dist.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Clean and group remote types\nremote_grouped = data[\"REMOTE_TYPE_NAME\"].fillna(\"Onsite\").replace({\n    \"[None]\": \"Onsite\", \n    \"Not Remote\": \"Onsite\",\n    \"None\": \"Onsite\"\n})\n\n# Count values\nremote_counts = remote_grouped.value_counts()\n\n# Define colors matching labels (make sure the order matches remote_counts.index)\ncolor_map = {\n    \"Onsite\": \"#297C8A\",\n    \"Hybrid Remote\": \"#78C2AD\",\n    \"Remote\": \"#F3969A\"\n}\n\n# Get colors for the pie chart slices in the correct order, fallback to gray if missing\ncolors = [color_map.get(label, \"#cccccc\") for label in remote_counts.index]\n\n# Plot pie chart\nplt.figure(figsize=(8, 8))\nwedges, texts, autotexts = plt.pie(\n    remote_counts.values,\n    labels=remote_counts.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    textprops={'fontsize': 14, 'color': 'black'}\n)\n\n# Title with larger font\nplt.title(\"Remote vs. On-Site Jobs\", fontsize=18, fontweight='bold', pad=20)\n\n# Adjust autotext (percentage text) font size\nfor autotext in autotexts:\n    autotext.set_fontsize(14)\n\n\nplt.savefig(\"figures/remote_onsite.png\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\nBar Chart: Job Postings by Industry\n\nMakes it easy to compare job postings across different industries.\n\nProvides a clear ranking that is simple to interpret.\n\nBoxplot: Salary Distribution by Industry\n\nShows medians, outliers, and summarizes salary distributions.\n\nAllows for comparisons between industries and helps detect salary variability.\n\nPie Chart: Job Location Types\n\nProvides a clear visual breakdown of remote versus on-site jobs within the dataset.\n\n\n\n\n\n\nBar Chart: Top 25 Industries by Job-Posting Volume\n\nThe distribution is skewed, showing demand concentrated in technology and professional services.\n\nA large portion of “unclassified industry” job postings suggests many jobs are not mapped to any industry.\n\nBoxplot: Salary Distribution by Industry\n\nSalaries across the 40 industries skew high, with medians generally in the $120k–$170k range.\n\nIndustries with higher medians and greater dispersions include software/semiconductors and consulting.\n\nSeveral industries have wide IQRs and many upper outliers, while some have less variability, indicating standardized pay.\n\nPie Chart: Job Location Types\n\n17% of jobs are remote, 3.1% are hybrid, and 1.6% are not remote.\n\nA large number of job postings do not specify whether the job is remote or on-site.\n\n\n\n\n\n\n\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Ava\", \"Mahira\", \"Joshua\"],\n    \"Python\": [2, 3, 3],\n    \"SQL\": [2, 1, 4],\n    \"Machine Learning\": [1, 3, 2],\n    \"Cloud Computing\": [1, 1, 1]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nAva\n2\n2\n1\n1\n\n\nMahira\n3\n1\n3\n1\n\n\nJoshua\n3\n4\n2\n1\n\n\n\n\n\n\n\n\n\n\n\nimport kaleido\nimport plotly.express as px\ncustom_colorscale = [\"#B14E53\", \"#78C2AD\", ]\nfig = px.imshow(df_skills,\n labels=dict(x=\"Skill\", y=\"Team Member Name\", color=\"Skill Self Rating\"),\n title=\"Key IT Skill Rating Heatmap per Team Member\",\n    color_continuous_scale=custom_colorscale\n)\nfig.update_layout(\n  title=dict(\n    text=\"Key IT Skill Rating Heatmap per Team Member\",\n    font=dict(size=18, family=\"Verdana\", color=\"black\", weight=\"bold\")\n  ),\n  xaxis=dict(\n    title=dict(text=\"Skill\", font=dict(size=20, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    tickangle=90,\n    tickfont=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\"),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n  ),\n  yaxis=dict(\n    title=dict(text=\"Teammember Name\", font=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n    gridcolor=\"white\",\n    gridwidth=0.5\n  ),\n  font=dict(family=\"Verdana\", size=14, color=\"black\"),\n  paper_bgcolor=\"white\",\n  showlegend=True,\n)\n\nfig.write_image(\"figures/skill_heatmap.png\")\nfig.write_html(\"figures/skill_heatmap.html\")\nfig.show()"
  },
  {
    "objectID": "data_analysis.html#importing-dataset-using-pandas",
    "href": "data_analysis.html#importing-dataset-using-pandas",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('./data/lightcast_job_postings.csv')\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_18744\\4222856436.py:4: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False."
  },
  {
    "objectID": "data_analysis.html#dropping-unncessary-columns",
    "href": "data_analysis.html#dropping-unncessary-columns",
    "title": "Data Analysis",
    "section": "",
    "text": "Which columns are irrelevant or redundant?\nID, URL, ACTIVE_URLS, DUPLICATES, LAST_UPDATED TIMESTAMP are irrelevant or redundant columns. They are mostly used for internal tracking and don’t contribute to the actual analysis of jobs, industries, and occupations.\nWhy are we removing multiple versions of NAICS/SOC codes?\nThe dataset contains multiple versions of industry NAICS and Occupational SOC which can be risky to keep, as there is risk of duplications and inconsistent groupings.\nHow will this improve analysis?\nThis will improve the analysis by enhancing the efficiency of the data; by having smaller datasets it will be easier to process and run data. It will also improve consistency because by having only one version of the data the risk of duplication will be low.\n\n\ncolumns_to_drop = [\n'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'EXPIRED', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW','BODY',\n'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS',\n'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP',\n'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING',\n'MSA_OUTGOING', 'MSA_NAME_OUTGOING','MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4','NAICS4_NAME',\n'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME',\n'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'LOT_OCCUPATION_GROUP_NAME',\n'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP',\n'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME',\n'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME',\n'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'MODELED_EXPIRED', 'MODELED_DURATION', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME',\n'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LIGHTCAST_SECTORS',\n'LIGHTCAST_SECTORS_NAME'\n]\ndata.drop(columns=columns_to_drop, inplace=True)"
  },
  {
    "objectID": "data_analysis.html#handling-missing-values",
    "href": "data_analysis.html#handling-missing-values",
    "title": "Data Analysis",
    "section": "",
    "text": "Answer the question: How should missing values be handled?\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Industry) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n\n\n# Fill missing values\ndata[\"SALARY\"].fillna(data[\"SALARY\"].median(), inplace=True)\ndata[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\", inplace=True)\ndata[\"REMOTE_TYPE_NAME\"].fillna(\"None, inplace=True\")\n\ndata.rename(columns={'NAICS_2022_6_NAME': 'INDUSTRY'}, inplace=True)\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_18744\\1830881447.py:7: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\nC:\\Users\\avago\\AppData\\Local\\Temp\\ipykernel_18744\\1830881447.py:8: FutureWarning:\n\nA value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n\ndata.dropna(thresh=len(data) * 0.5, axis=1, inplace=True)\n\n# Visualize missing data\nimport matplotlib as mpl\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Set global font settings\nmpl.rcParams['font.family'] = 'Verdana'\nmpl.rcParams['font.size'] = 14\nmpl.rcParams['text.color'] = 'black'\nmpl.rcParams['axes.labelcolor'] = 'black'\nmpl.rcParams['xtick.color'] = 'black'\nmpl.rcParams['ytick.color'] = 'black'\n\n# Define custom green-to-red colormap\ncustom_cmap = LinearSegmentedColormap.from_list(\n    'custom_green_red', ['#B14E53', '#78C2AD'], N=256\n)\n\n# Create the heatmap\nfig = plt.figure(figsize=(10, 6))\nax = msno.heatmap(data, cmap=custom_cmap)\n\n# Set the title\nplt.title(\"Missing Values Heatmap\", fontsize=18, fontweight='bold')\n\nplt.savefig(\"figures/missing_values.png\")\nplt.show()\n\n&lt;Figure size 960x576 with 0 Axes&gt;\n\n\n\n\n\n\n\n\n\n\nThe heatmap shows a few missing values in the dataset. In this dataset most fields cluster near 1. The value 1 (dark blue) means the two columns have missing values together. 0.0 value (white) suggest there is no relationship."
  },
  {
    "objectID": "data_analysis.html#remove-duplicates",
    "href": "data_analysis.html#remove-duplicates",
    "title": "Data Analysis",
    "section": "",
    "text": "data = data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
  },
  {
    "objectID": "data_analysis.html#job-postings-by-industry",
    "href": "data_analysis.html#job-postings-by-industry",
    "title": "Data Analysis",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Compute posting count per industry\ndata[\"posting_count\"] = data[\"ID\"].groupby(data[\"INDUSTRY\"]).transform(\"count\")\n\n# Summarize and sort top 25 industries\nindustry_summary = data.groupby(\"INDUSTRY\")[\"posting_count\"].first().sort_values(ascending=False).head(25)\n\n# Plot\nplt.figure(figsize=(12, 10))\nsns.barplot(\n    x=industry_summary.values,\n    y=industry_summary.index,\n    orient='h',\n    color='#6CC3D5'\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Top 25 Job Postings by Industry\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Number of Job Postings\", fontsize=14)\nplt.ylabel(\"Industry\", fontsize=14)\n\nplt.tight_layout()\n\nplt.savefig(\"figures/top_postings.png\")\nplt.show()"
  },
  {
    "objectID": "data_analysis.html#salary-distribution-by-industry",
    "href": "data_analysis.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "",
    "text": "import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Calculate average industry salary\ndata[\"AVERAGE_INDUSTRY_SALARY\"] = data[\"SALARY\"].groupby(data[\"INDUSTRY\"]).transform(\"mean\").round()\n\n# Get top 40 industries by average salary\ntop_40_industries = data.groupby(\"INDUSTRY\")[\"AVERAGE_INDUSTRY_SALARY\"].first().sort_values(ascending=False).head(40).index\nfiltered_data = data[data[\"INDUSTRY\"].isin(top_40_industries)]\n\n# Create figure with taller height\nplt.figure(figsize=(20, 14))  # Increased height from 10 to 14\n\n# Create boxplot with custom color\nsns.boxplot(\n    data=filtered_data,\n    x=\"INDUSTRY\",\n    y=\"SALARY\",\n    order=top_40_industries,\n    color='#F3969A'  # Custom box color\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Salary Distribution by Industry (Top 40 by Average Salary)\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Industry\", fontsize=14)\nplt.ylabel(\"Salary\", fontsize=14)\n\n# Rotate x-tick labels for readability\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\n\n\nplt.savefig(\"figures/salary_dist.png\")\nplt.show()"
  },
  {
    "objectID": "data_analysis.html#remote-vs.-on-site-jobs",
    "href": "data_analysis.html#remote-vs.-on-site-jobs",
    "title": "Data Analysis",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Clean and group remote types\nremote_grouped = data[\"REMOTE_TYPE_NAME\"].fillna(\"Onsite\").replace({\n    \"[None]\": \"Onsite\", \n    \"Not Remote\": \"Onsite\",\n    \"None\": \"Onsite\"\n})\n\n# Count values\nremote_counts = remote_grouped.value_counts()\n\n# Define colors matching labels (make sure the order matches remote_counts.index)\ncolor_map = {\n    \"Onsite\": \"#297C8A\",\n    \"Hybrid Remote\": \"#78C2AD\",\n    \"Remote\": \"#F3969A\"\n}\n\n# Get colors for the pie chart slices in the correct order, fallback to gray if missing\ncolors = [color_map.get(label, \"#cccccc\") for label in remote_counts.index]\n\n# Plot pie chart\nplt.figure(figsize=(8, 8))\nwedges, texts, autotexts = plt.pie(\n    remote_counts.values,\n    labels=remote_counts.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    textprops={'fontsize': 14, 'color': 'black'}\n)\n\n# Title with larger font\nplt.title(\"Remote vs. On-Site Jobs\", fontsize=18, fontweight='bold', pad=20)\n\n# Adjust autotext (percentage text) font size\nfor autotext in autotexts:\n    autotext.set_fontsize(14)\n\n\nplt.savefig(\"figures/remote_onsite.png\")\nplt.show()"
  },
  {
    "objectID": "data_analysis.html#why-these-visualizations-were-chosen",
    "href": "data_analysis.html#why-these-visualizations-were-chosen",
    "title": "Data Analysis",
    "section": "",
    "text": "Bar Chart: Job Postings by Industry\n\nMakes it easy to compare job postings across different industries.\n\nProvides a clear ranking that is simple to interpret.\n\nBoxplot: Salary Distribution by Industry\n\nShows medians, outliers, and summarizes salary distributions.\n\nAllows for comparisons between industries and helps detect salary variability.\n\nPie Chart: Job Location Types\n\nProvides a clear visual breakdown of remote versus on-site jobs within the dataset."
  },
  {
    "objectID": "data_analysis.html#key-insights-from-each-graph",
    "href": "data_analysis.html#key-insights-from-each-graph",
    "title": "Data Analysis",
    "section": "",
    "text": "Bar Chart: Top 25 Industries by Job-Posting Volume\n\nThe distribution is skewed, showing demand concentrated in technology and professional services.\n\nA large portion of “unclassified industry” job postings suggests many jobs are not mapped to any industry.\n\nBoxplot: Salary Distribution by Industry\n\nSalaries across the 40 industries skew high, with medians generally in the $120k–$170k range.\n\nIndustries with higher medians and greater dispersions include software/semiconductors and consulting.\n\nSeveral industries have wide IQRs and many upper outliers, while some have less variability, indicating standardized pay.\n\nPie Chart: Job Location Types\n\n17% of jobs are remote, 3.1% are hybrid, and 1.6% are not remote.\n\nA large number of job postings do not specify whether the job is remote or on-site."
  },
  {
    "objectID": "data_analysis.html#team-skill-level-dataframe",
    "href": "data_analysis.html#team-skill-level-dataframe",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\n\nskills_data = {\n    \"Name\": [\"Ava\", \"Mahira\", \"Joshua\"],\n    \"Python\": [2, 3, 3],\n    \"SQL\": [2, 1, 4],\n    \"Machine Learning\": [1, 3, 2],\n    \"Cloud Computing\": [1, 1, 1]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills\n\n\n\n\n\n\n\n\nPython\nSQL\nMachine Learning\nCloud Computing\n\n\nName\n\n\n\n\n\n\n\n\nAva\n2\n2\n1\n1\n\n\nMahira\n3\n1\n3\n1\n\n\nJoshua\n3\n4\n2\n1"
  },
  {
    "objectID": "data_analysis.html#visualizing-skill-gaps-in-heatmap-with-plotly",
    "href": "data_analysis.html#visualizing-skill-gaps-in-heatmap-with-plotly",
    "title": "Data Analysis",
    "section": "",
    "text": "import kaleido\nimport plotly.express as px\ncustom_colorscale = [\"#B14E53\", \"#78C2AD\", ]\nfig = px.imshow(df_skills,\n labels=dict(x=\"Skill\", y=\"Team Member Name\", color=\"Skill Self Rating\"),\n title=\"Key IT Skill Rating Heatmap per Team Member\",\n    color_continuous_scale=custom_colorscale\n)\nfig.update_layout(\n  title=dict(\n    text=\"Key IT Skill Rating Heatmap per Team Member\",\n    font=dict(size=18, family=\"Verdana\", color=\"black\", weight=\"bold\")\n  ),\n  xaxis=dict(\n    title=dict(text=\"Skill\", font=dict(size=20, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    tickangle=90,\n    tickfont=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\"),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n  ),\n  yaxis=dict(\n    title=dict(text=\"Teammember Name\", font=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n    gridcolor=\"white\",\n    gridwidth=0.5\n  ),\n  font=dict(family=\"Verdana\", size=14, color=\"black\"),\n  paper_bgcolor=\"white\",\n  showlegend=True,\n)\n\nfig.write_image(\"figures/skill_heatmap.png\")\nfig.write_html(\"figures/skill_heatmap.html\")\nfig.show()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome\nWelcome to Group 2’s report on Salary and Compensation Trends for AI Careers. Use the navigation bar above to view the report."
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "research_introduction.html#introduction",
    "href": "research_introduction.html#introduction",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "research_introduction.html#literature-review",
    "href": "research_introduction.html#literature-review",
    "title": "Research Introduction: Salary & Compensation Trends",
    "section": "Literature Review",
    "text": "Literature Review\nIn this report, researchers Alekseeva et. al. (Alekseeva et al. ((2021))) recapped their findings of the demand for AI skills in the U.S. economy. The authors point out that it can be difficult to find data regarding companies’ demand for AI skills, so they used job posting data. They defined AI job postings as those that included “artificial intelligence”, “machine vision”, “deep learning” or “speech recognition”. They found that larger firms (measured by market capitalization, cash holdings, and investments in R&D) tended to pay more of a premium for AI skills. Firms with more demand for AI skills also offered high salaries in non-AI jobs than firms with less demand for AI skills.\n\nThe results also showed that while IT-related industries have the highest demand for AI skills, there is significant growth across a wide range of industries outside of IT as well. Across all industries, AI skills hold an average of an 11% wage premium. The job with the largest premium is Management; the authors surmise that this means AI has the greatest value when combined with organizational knowledge.\n\nAuthors Pabilonia and Vernon outline differences in compensation for remote and in-office roles (Pabilonia and Vernon ((2025))). Using data from American Time Use Survey (ATUS) they note that remote work has increased in the US since 2020 (causal connection with the COVID-19 pandemic), and importantly “remote workers in most occupations earned a wage premium”. The authors performed extensive mathematical analysis within the paper, determining that in 2021 there was a 13.3% premium for remote work versus in-office work. Wages within the paper are indicated as being “determined by a number of factors, including job tasks, productivity differences, compensating differentials for job amenities, search frictions, and monopsony power, among others”. The authors also touched on disparity in pay within the principal city of the large metropolitan statistical area (MSA), noting that the wage premium for individuals working within the MSA was smaller (12.6%) than those working outside the 15 largest MDAs (14.5%).\n\nCard et. al. (Card, Rothstein, and Yi ((2023))) discuss the locale for the highest paid jobs within the US. Unsurprisingly, using “data from the Longitudinal Employer-Household Dynamics program” the authors demonstrate connections between location and salary. Regions in major metropolitans and large industries have wage premiums up to 18% higher than national averages. The authors theorize that larger cities pay more due to their ability to attract and retain higher-skilled workers and the likely presence of large companies to support the talent. The authors do however also find that despite the higher wages in the major commuting zones (CZs), local costs “fully offset local pay premiums, implying that workers who move to larger CZs have no higher net-of-housing consumption”. This leads to the understanding that while more highly compensated in major metropolitan areas, the cost of living consumes the wage premium.\n\nAccording to the U.S. Bureau of Labor Statistics (BLS) (Labor Statistics ((2024))), total employment is projected to grow by 4 percent between 2023 and 2033. There is also an expected increase in the number of jobs from 2023 to 2033 from 167.8 million to 17.46 million. Half of the forecasted job gains are expected to be in sectors such as healthcare, scientific and technical services. Whereas, the retail sector is more likely to lose jobs over the coming years.\n\nIndustries that will see the most significant wage growth from 2023 and 2033 are those that will have a strong demand for specialized labor. Healthcare and social assistance jobs will see a rise in high paying roles such as nurse practitioners and physical therapists assistants. This sector will experience continued growth due to skill labor shortages and aging population. The scientific and technical services sector is expected to grow by 10.5% and it includes high paying roles such as software developers, cybersecurity professionals and data scientists. Renewable Energy industries sector will see an increase in jobs over the years as demand for photovoltaic installers and wind turbines service technicians is increasing and are expected to be hired at competitive rates."
  },
  {
    "objectID": "final_report.html",
    "href": "final_report.html",
    "title": "Data Analysis",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "final_report.html#introduction",
    "href": "final_report.html#introduction",
    "title": "Data Analysis",
    "section": "",
    "text": "It is no secret that AI has grown tremendously in availability and impact over the last few years. Students and professionals alike have experienced a rapid indoctrination of AI, whether that be as a simple end-user of ChatGPT or a developer of machine learning models. Being able to understand and adopt these technologies will be indispensable for all industries, and furthermore, open the door to more opportunities with higher compensation.\n\nAs Applied Business Analytics students, we understand the importance of not only computer science knowledge, but the application of that knowledge to broader organizational understanding. The following literature review outlines the differences between salaries for AI vs. non-AI careers, regional differences, remote job salary comparisons, and industry comparisons.\n\nThis group expects that salaries will be higher for AI careers than for non-AI careers on average. However, unknown is what region and industries have the greatest differences, and whether or not remote status impacts salaries for AI careers."
  },
  {
    "objectID": "final_report.html#literature-review",
    "href": "final_report.html#literature-review",
    "title": "Data Analysis",
    "section": "Literature Review",
    "text": "Literature Review\nIn this report, researchers Alekseeva et. al. (Alekseeva et al. ((2021))) recapped their findings of the demand for AI skills in the U.S. economy. The authors point out that it can be difficult to find data regarding companies’ demand for AI skills, so they used job posting data. They defined AI job postings as those that included “artificial intelligence”, “machine vision”, “deep learning” or “speech recognition”. They found that larger firms (measured by market capitalization, cash holdings, and investments in R&D) tended to pay more of a premium for AI skills. Firms with more demand for AI skills also offered high salaries in non-AI jobs than firms with less demand for AI skills.\n\nThe results also showed that while IT-related industries have the highest demand for AI skills, there is significant growth across a wide range of industries outside of IT as well. Across all industries, AI skills hold an average of an 11% wage premium. The job with the largest premium is Management; the authors surmise that this means AI has the greatest value when combined with organizational knowledge.\n\nAuthors Pabilonia and Vernon outline differences in compensation for remote and in-office roles (Pabilonia and Vernon ((2025))). Using data from American Time Use Survey (ATUS) they note that remote work has increased in the US since 2020 (causal connection with the COVID-19 pandemic), and importantly “remote workers in most occupations earned a wage premium”. The authors performed extensive mathematical analysis within the paper, determining that in 2021 there was a 13.3% premium for remote work versus in-office work. Wages within the paper are indicated as being “determined by a number of factors, including job tasks, productivity differences, compensating differentials for job amenities, search frictions, and monopsony power, among others”. The authors also touched on disparity in pay within the principal city of the large metropolitan statistical area (MSA), noting that the wage premium for individuals working within the MSA was smaller (12.6%) than those working outside the 15 largest MDAs (14.5%).\n\nCard et. al. (Card, Rothstein, and Yi ((2023))) discuss the locale for the highest paid jobs within the US. Unsurprisingly, using “data from the Longitudinal Employer-Household Dynamics program” the authors demonstrate connections between location and salary. Regions in major metropolitans and large industries have wage premiums up to 18% higher than national averages. The authors theorize that larger cities pay more due to their ability to attract and retain higher-skilled workers and the likely presence of large companies to support the talent. The authors do however also find that despite the higher wages in the major commuting zones (CZs), local costs “fully offset local pay premiums, implying that workers who move to larger CZs have no higher net-of-housing consumption”. This leads to the understanding that while more highly compensated in major metropolitan areas, the cost of living consumes the wage premium.\n\nAccording to the U.S. Bureau of Labor Statistics (BLS) (Labor Statistics ((2024))), total employment is projected to grow by 4 percent between 2023 and 2033. There is also an expected increase in the number of jobs from 2023 to 2033 from 167.8 million to 17.46 million. Half of the forecasted job gains are expected to be in sectors such as healthcare, scientific and technical services. Whereas, the retail sector is more likely to lose jobs over the coming years.\n\nIndustries that will see the most significant wage growth from 2023 and 2033 are those that will have a strong demand for specialized labor. Healthcare and social assistance jobs will see a rise in high paying roles such as nurse practitioners and physical therapists assistants. This sector will experience continued growth due to skill labor shortages and aging population. The scientific and technical services sector is expected to grow by 10.5% and it includes high paying roles such as software developers, cybersecurity professionals and data scientists. Renewable Energy industries sector will see an increase in jobs over the years as demand for photovoltaic installers and wind turbines service technicians is increasing and are expected to be hired at competitive rates."
  },
  {
    "objectID": "final_report.html#references",
    "href": "final_report.html#references",
    "title": "Data Analysis",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "final_report.html#importing-dataset-using-pandas",
    "href": "final_report.html#importing-dataset-using-pandas",
    "title": "Data Analysis",
    "section": "Importing Dataset Using Pandas",
    "text": "Importing Dataset Using Pandas\n\nimport pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('./data/lightcast_job_postings.csv')"
  },
  {
    "objectID": "final_report.html#dropping-unncessary-columns",
    "href": "final_report.html#dropping-unncessary-columns",
    "title": "Data Analysis",
    "section": "Dropping Unncessary Columns",
    "text": "Dropping Unncessary Columns\n\nWhich columns are irrelevant or redundant?\nID, URL, ACTIVE_URLS, DUPLICATES, LAST_UPDATED TIMESTAMP are irrelevant or redundant columns. They are mostly used for internal tracking and don’t contribute to the actual analysis of jobs, industries, and occupations.\nWhy are we removing multiple versions of NAICS/SOC codes?\nThe dataset contains multiple versions of industry NAICS and Occupational SOC which can be risky to keep, as there is risk of duplications and inconsistent groupings.\nHow will this improve analysis?\nThis will improve the analysis by enhancing the efficiency of the data; by having smaller datasets it will be easier to process and run data. It will also improve consistency because by having only one version of the data the risk of duplication will be low.\n\n\ncolumns_to_drop = [\n'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'EXPIRED', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW','BODY',\n'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS',\n'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP',\n'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING',\n'MSA_OUTGOING', 'MSA_NAME_OUTGOING','MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4','NAICS4_NAME',\n'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME',\n'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'LOT_OCCUPATION_GROUP_NAME',\n'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP',\n'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME',\n'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME',\n'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'MODELED_EXPIRED', 'MODELED_DURATION', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME',\n'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LIGHTCAST_SECTORS',\n'LIGHTCAST_SECTORS_NAME'\n]\ndata.drop(columns=columns_to_drop, inplace=True)"
  },
  {
    "objectID": "final_report.html#handling-missing-values",
    "href": "final_report.html#handling-missing-values",
    "title": "Data Analysis",
    "section": "Handling Missing Values",
    "text": "Handling Missing Values\n\nAnswer the question: How should missing values be handled?\n\nNumerical fields (e.g., Salary) are filled with the median.\nCategorical fields (e.g., Industry) are replaced with “Unknown”.\nColumns with &gt;50% missing values are dropped.\n\n\n\nimport missingno as msno\nimport matplotlib.pyplot as plt\n\n\n\n# Fill missing values\ndata[\"SALARY\"].fillna(data[\"SALARY\"].median(), inplace=True)\ndata[\"NAICS_2022_6_NAME\"].fillna(\"Unknown\", inplace=True)\ndata[\"REMOTE_TYPE_NAME\"].fillna(\"None, inplace=True\")\n\ndata.rename(columns={'NAICS_2022_6_NAME': 'INDUSTRY'}, inplace=True)\n\n\ndata.dropna(thresh=len(data) * 0.5, axis=1, inplace=True)\n\n# Visualize missing data\nimport matplotlib as mpl\nfrom matplotlib.colors import LinearSegmentedColormap\n\n# Set global font settings\nmpl.rcParams['font.family'] = 'Verdana'\nmpl.rcParams['font.size'] = 14\nmpl.rcParams['text.color'] = 'black'\nmpl.rcParams['axes.labelcolor'] = 'black'\nmpl.rcParams['xtick.color'] = 'black'\nmpl.rcParams['ytick.color'] = 'black'\n\n# Define custom green-to-red colormap\ncustom_cmap = LinearSegmentedColormap.from_list(\n    'custom_green_red', ['#B14E53', '#78C2AD'], N=256\n)\n\n# Create the heatmap\nfig = plt.figure(figsize=(10, 6))\nax = msno.heatmap(data, cmap=custom_cmap)\n\n# Set the title\nplt.title(\"Missing Values Heatmap\", fontsize=18, fontweight='bold')\n\nplt.savefig(\"figures/missing_values.png\")\nplt.show()\n\n\nThe heatmap shows a few missing values in the dataset. In this dataset most fields cluster near 1. The value 1 (dark blue) means the two columns have missing values together. 0.0 value (white) suggest there is no relationship."
  },
  {
    "objectID": "final_report.html#remove-duplicates",
    "href": "final_report.html#remove-duplicates",
    "title": "Data Analysis",
    "section": "Remove Duplicates",
    "text": "Remove Duplicates\n\ndata = data.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")"
  },
  {
    "objectID": "final_report.html#job-postings-by-industry",
    "href": "final_report.html#job-postings-by-industry",
    "title": "Data Analysis",
    "section": "Job Postings by Industry",
    "text": "Job Postings by Industry\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Compute posting count per industry\ndata[\"posting_count\"] = data[\"ID\"].groupby(data[\"INDUSTRY\"]).transform(\"count\")\n\n# Summarize and sort top 25 industries\nindustry_summary = data.groupby(\"INDUSTRY\")[\"posting_count\"].first().sort_values(ascending=False).head(25)\n\n# Plot\nplt.figure(figsize=(12, 10))\nsns.barplot(\n    x=industry_summary.values,\n    y=industry_summary.index,\n    orient='h',\n    color='#6CC3D5'\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Top 25 Job Postings by Industry\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Number of Job Postings\", fontsize=14)\nplt.ylabel(\"Industry\", fontsize=14)\n\nplt.tight_layout()\nplt.show()\nplt.savefig(\"figures/top_postings.png\")"
  },
  {
    "objectID": "final_report.html#salary-distribution-by-industry",
    "href": "final_report.html#salary-distribution-by-industry",
    "title": "Data Analysis",
    "section": "Salary Distribution by Industry",
    "text": "Salary Distribution by Industry\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Calculate average industry salary\ndata[\"AVERAGE_INDUSTRY_SALARY\"] = data[\"SALARY\"].groupby(data[\"INDUSTRY\"]).transform(\"mean\").round()\n\n# Get top 40 industries by average salary\ntop_40_industries = data.groupby(\"INDUSTRY\")[\"AVERAGE_INDUSTRY_SALARY\"].first().sort_values(ascending=False).head(40).index\nfiltered_data = data[data[\"INDUSTRY\"].isin(top_40_industries)]\n\n# Create figure with taller height\nplt.figure(figsize=(20, 14))  # Increased height from 10 to 14\n\n# Create boxplot with custom color\nsns.boxplot(\n    data=filtered_data,\n    x=\"INDUSTRY\",\n    y=\"SALARY\",\n    order=top_40_industries,\n    color='#F3969A'  # Custom box color\n)\n\n# Title and labels with updated font sizes\nplt.title(\"Salary Distribution by Industry (Top 40 by Average Salary)\", fontsize=18, fontweight='bold', pad=20)\nplt.xlabel(\"Industry\", fontsize=14)\nplt.ylabel(\"Salary\", fontsize=14)\n\n# Rotate x-tick labels for readability\nplt.xticks(rotation=45, ha='right')\n\nplt.tight_layout()\nplt.show()\n\nplt.savefig(\"figures/salary_dist.png\")"
  },
  {
    "objectID": "final_report.html#remote-vs.-on-site-jobs",
    "href": "final_report.html#remote-vs.-on-site-jobs",
    "title": "Data Analysis",
    "section": "Remote vs. On-Site Jobs",
    "text": "Remote vs. On-Site Jobs\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n# Set global font family to Verdana\nmpl.rcParams['font.family'] = 'Verdana'\n\n# Clean and group remote types\nremote_grouped = data[\"REMOTE_TYPE_NAME\"].fillna(\"Onsite\").replace({\n    \"[None]\": \"Onsite\", \n    \"Not Remote\": \"Onsite\",\n    \"None\": \"Onsite\"\n})\n\n# Count values\nremote_counts = remote_grouped.value_counts()\n\n# Define colors matching labels (make sure the order matches remote_counts.index)\ncolor_map = {\n    \"Onsite\": \"#297C8A\",\n    \"Hybrid Remote\": \"#78C2AD\",\n    \"Remote\": \"#F3969A\"\n}\n\n# Get colors for the pie chart slices in the correct order, fallback to gray if missing\ncolors = [color_map.get(label, \"#cccccc\") for label in remote_counts.index]\n\n# Plot pie chart\nplt.figure(figsize=(8, 8))\nwedges, texts, autotexts = plt.pie(\n    remote_counts.values,\n    labels=remote_counts.index,\n    autopct='%1.1f%%',\n    colors=colors,\n    textprops={'fontsize': 14, 'color': 'black'}\n)\n\n# Title with larger font\nplt.title(\"Remote vs. On-Site Jobs\", fontsize=18, fontweight='bold', pad=20)\n\n# Adjust autotext (percentage text) font size\nfor autotext in autotexts:\n    autotext.set_fontsize(14)\n\nplt.show()\nplt.savefig(\"figures/remote_onsite.png\")"
  },
  {
    "objectID": "final_report.html#why-these-visualizations-were-chosen",
    "href": "final_report.html#why-these-visualizations-were-chosen",
    "title": "Data Analysis",
    "section": "Why these visualizations were chosen",
    "text": "Why these visualizations were chosen\n\nBar Chart: Job Postings by Industry\n\nMakes it easy to compare job postings across different industries.\n\nProvides a clear ranking that is simple to interpret.\n\nBoxplot: Salary Distribution by Industry\n\nShows medians, outliers, and summarizes salary distributions.\n\nAllows for comparisons between industries and helps detect salary variability.\n\nPie Chart: Job Location Types\n\nProvides a clear visual breakdown of remote versus on-site jobs within the dataset."
  },
  {
    "objectID": "final_report.html#key-insights-from-each-graph",
    "href": "final_report.html#key-insights-from-each-graph",
    "title": "Data Analysis",
    "section": "Key insights from each graph",
    "text": "Key insights from each graph\n\nBar Chart: Top 25 Industries by Job-Posting Volume\n\nThe distribution is skewed, showing demand concentrated in technology and professional services.\n\nA large portion of “unclassified industry” job postings suggests many jobs are not mapped to any industry.\n\nBoxplot: Salary Distribution by Industry\n\nSalaries across the 40 industries skew high, with medians generally in the $120k–$170k range.\n\nIndustries with higher medians and greater dispersions include software/semiconductors and consulting.\n\nSeveral industries have wide IQRs and many upper outliers, while some have less variability, indicating standardized pay.\n\nPie Chart: Job Location Types\n\n17% of jobs are remote, 3.1% are hybrid, and 1.6% are not remote.\n\nA large number of job postings do not specify whether the job is remote or on-site."
  },
  {
    "objectID": "final_report.html#team-skill-level-dataframe",
    "href": "final_report.html#team-skill-level-dataframe",
    "title": "Data Analysis",
    "section": "Team Skill Level Dataframe",
    "text": "Team Skill Level Dataframe\n\n\nimport pandas as pd\n\nskills_data = {\n    \"Name\": [\"Ava\", \"Mahira\", \"Joshua\"],\n    \"Python\": [2, 3, 3],\n    \"SQL\": [2, 1, 4],\n    \"Machine Learning\": [1, 3, 2],\n    \"Cloud Computing\": [1, 1, 1]\n}\n\ndf_skills = pd.DataFrame(skills_data)\ndf_skills.set_index(\"Name\", inplace=True)\ndf_skills"
  },
  {
    "objectID": "final_report.html#visualizing-skill-gaps-in-heatmap-with-plotly",
    "href": "final_report.html#visualizing-skill-gaps-in-heatmap-with-plotly",
    "title": "Data Analysis",
    "section": "Visualizing Skill Gaps in Heatmap with Plotly",
    "text": "Visualizing Skill Gaps in Heatmap with Plotly\n\nimport kaleido\nimport plotly.express as px\ncustom_colorscale = [\"#B14E53\", \"#78C2AD\", ]\nfig = px.imshow(df_skills,\n labels=dict(x=\"Skill\", y=\"Team Member Name\", color=\"Skill Self Rating\"),\n title=\"Key IT Skill Rating Heatmap per Team Member\",\n    color_continuous_scale=custom_colorscale\n)\nfig.update_layout(\n  title=dict(\n    text=\"Key IT Skill Rating Heatmap per Team Member\",\n    font=dict(size=18, family=\"Verdana\", color=\"black\", weight=\"bold\")\n  ),\n  xaxis=dict(\n    title=dict(text=\"Skill\", font=dict(size=20, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    tickangle=90,\n    tickfont=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\"),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n  ),\n  yaxis=dict(\n    title=dict(text=\"Teammember Name\", font=dict(size=14, family=\"Verdana\", color=\"black\", weight=\"bold\")),\n    showline=True,\n    linewidth=2,\n    linecolor=\"black\",\n    mirror=True,\n    showgrid=True,\n    gridcolor=\"white\",\n    gridwidth=0.5\n  ),\n  font=dict(family=\"Verdana\", size=14, color=\"black\"),\n  paper_bgcolor=\"white\",\n  showlegend=True,\n)\nfig.show()\nfig.write_image(\"figures/skill_heatmap.png\")\nfig.write_html(\"figures/skill_heatmap.html\")\n\n\n\ntitle: “Skill Gap Analysis” author: - name: Mahira Ayub affiliations: - id: bu name: Boston University city: Boston state: MA - name: Ava Godsy affiliations: - ref: bu - name: Joshua Lawrence affiliations: - ref: bu execute: eval: false —\n\nimport pandas as pd\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\nfiltered_df = df[[\"ID\", \"BODY\"]]\nfiltered_df = filtered_df.dropna()\n\n\n# Assuming job_descriptions is a list of text from job postings\ntop_skills = [\"Python\", \"SQL\", \"Machine Learning\", \"Cloud Computing\", \"Docker\", \"AWS\"]\n\nskill_counts = {}\nfor skill in top_skills:\n    skill_counts[skill] = filtered_df[\"BODY\"].str.contains(skill, case=False, na=False).sum()\n\nskills_df_pd = pd.DataFrame(list(skill_counts.items()), columns=['Skill', 'Count'])\n\nprint(skills_df_pd)\nskills_df_pd.to_csv(\"data/skills_job_description.csv\", index=False)\n\n\nimport plotly.express as px\n\ntop_skills_fig = px.bar(\n    skills_df_pd,\n    x='Skill',\n    y='Count',\n    title='Bar Chart of Job Description Skill Occurence',\n    color_discrete_sequence=['#3D7C6A']  # Set bar color\n)\n\n# Update layout for fonts and sizes\ntop_skills_fig.update_layout(\n    font=dict(\n        family=\"Verdana\",\n        size=14,\n        color=\"black\"\n    ),\n    title=dict(\n        font=dict(\n            family=\"Verdana\",\n            size=18,\n            color=\"black\"\n        )\n    ),\n    xaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    ),\n    yaxis=dict(\n        title_font=dict(\n            family=\"Verdana\",\n            size=14,\n            color=\"black\"\n        )\n    )\n)\n\ntop_skills_fig.show()\ntop_skills_fig.write_image(\"./figures/top_skills.png\")\ntop_skills_fig.write_html(\"./figures/top_skills.html\")"
  }
]